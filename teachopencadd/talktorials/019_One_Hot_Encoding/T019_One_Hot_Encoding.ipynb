{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talktorial 3\n",
    "\n",
    "# The One-Hot Encoding Concept\n",
    "\n",
    "#### CADD Seminar 2020, AG Volkamer, Charité/FU Berlin \n",
    "\n",
    "#### SAKSHI MISRA\n",
    "\n",
    "Berlin,May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Aim of this talkatorial\n",
    "\n",
    "The aim of the talkatorial is to perform One Hot Encoding on SMILES structures of ChEMBL dataset to gain a deeper understanding on One Hot Encoding Concept and why it is useful as a pre-processing step in various Machine Learning algorithm.\n",
    "\n",
    "<img src=\"./images/logo.png\" width=\"300\" align='center'>\n",
    "\n",
    "# Learning goals\n",
    "\n",
    "\n",
    "## Theory\n",
    "\n",
    "* ChEMBL database\n",
    "* SMILES structures\n",
    "    - Some SMILES Specification Rules\n",
    "* What is Categorical Data?\n",
    "    - What is the Problem with Categorical Data?\n",
    "    - How to Convert Categorical Data to Numerical Data?\n",
    "* One Hot Encoding Concept\n",
    "    - Why Use a One Hot Encoding?\n",
    "    - Example of One Hot Encoding\n",
    "    - Advantages of Using One Hot Encoding\n",
    "    - Disadvantages of Using One Hot Encoding\n",
    "* Other similar Transformation\n",
    "    - Integer Encoding (Label Encoder)\n",
    "    - Example of Label Encoding\n",
    "* Differences between Label and One Hot Encoding\n",
    "* Further Readings\n",
    "\n",
    "\n",
    "## Practical\n",
    "\n",
    "* Import necessary packages\n",
    "* Load and draw molecules\n",
    "* Apply One Hot encoding using own implementation\n",
    "  - Visualization of One Hot Encoded Matrix using Own Implementation (unequal dimension)\n",
    "* Function defined to preprocess the Data\n",
    "* Apply One Hot encoding using Own implementation on Preprocessed Data\n",
    "  - Visualization of One Hot Encoded Matrix using Own Implementation (equal dimension)\n",
    "* Apply One Hot encoding using implementation in [Scikit-learn](https://scikitlearn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "   - Without Padding\n",
    "     - Visualization using Scikit-learn implementation\n",
    "   - Padding after One Hot Encoding performed\n",
    "      - Visualization using Scikit-learn implementation\n",
    "   - Padding before One Hot Encoding performed\n",
    "      - Visualization using Scikit-learn implementation\n",
    "* Apply One Hot encoding using implementation in [keras](https://keras.io/)\n",
    "  - Without Padding\n",
    "     - Visualization of One Hot Encoded Matrix using keras implementation\n",
    "  - With Padding\n",
    "     - Visualization of One Hot Encoded Matrix using keras implementation\n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "- Theoretical Background:\n",
    "     - ChEMBL database (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3965067/)\n",
    "     - Example using OneHotEncoder function from Scikit Learn (https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)\n",
    "     \n",
    "\n",
    "- Packages used:\n",
    "     - rdkit (https://www.rdkit.org/docs/GettingStartedInPython.html)\n",
    "     - Scikit-learn (https://scikit-learn.org/stable/)\n",
    "     - keras (https://keras.io/)\n",
    "     - Matplotlib (https://matplotlib.org/)\n",
    "     - timeit (https://docs.python.org/3/library/timeit.html)\n",
    "     \n",
    "- Smiles Encoder function used (https://iwatobipen.wordpress.com/2017/01/22/encode-and-decode-smiles-strings/)\n",
    "\n",
    "- Images used:\n",
    "     - Figure 1- Categorical Encoding (https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/)\n",
    "     - Figure 2- One Hot Encoding of SMILES(https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2523-5)\n",
    "     - Figure 3- One hot Encoding example (https://towardsdatascience.com/building-a-one-hot-encoding-layer-with-tensorflow-f907d686bf39)\n",
    "     - Figure 4- Label encoding example  (https://towardsdatascience.com/know-about-categorical-encoding-even-new-ones-c266227b9cbd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "## ChEMBL database\n",
    "\n",
    "- [ChEMBL](https://www.ebi.ac.uk/chembl/) is an open large-scale bioactivity database. \n",
    "- It is a database having molecules with drug-like properties. \n",
    "- Recent release 17 contains information extracted from  more than 51,000 publications, together with bioactivity   data sets from 18 other sources (depositors and databases). In total, there are now more than 1.3 million distinct compound structures and 12 million bioactivity data points.\n",
    "- It is maintained by [European Bioinformatics Institute](https://en.wikipedia.org/wiki/European_Bioinformatics_Institute).\n",
    "\n",
    "\n",
    "## SMILES structures\n",
    "- [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) (Simplified Molecular Input Line Entry System) notation is a chemical notation that allows a user to represent a chemical structure of a molecule in a linear way that can be used by the computer.\n",
    "- SMILES contains a chain of letters, number and characters that specify the atoms, their connectivity , their bond order and chirality.\n",
    "\n",
    " > ### Some SMILES Specification Rules\n",
    "    - **Atoms** - are represented by their atomic symbols. Also metal atoms are represented with symbols in square bracket, for eg. Gold `[Au]`.\n",
    "    - **Bonds** - Single, Double and Triple bonds are represented by symbols `-`, `=` and `#` respectively.Aromatic bonds are represented by `*`. Single bonds are the default and therefore need not be entered. Aromatic C,O,S and N atoms are shown in lower case like 'c', 'o', 's' and 'n' or by symbo ':' whereas Aliphatic C,O,S and N atoms are shown in upper case. For example, 'CC' would mean that there is a non-aromatic carbon attached to another non-aromatic carbon by a single bond, and the computer would identify the structure as the chemical Ethane (`CH3CH3`).\n",
    "    - **Rings** - SMILES allows a user to identify ring structures by using numbers to identify the opening and closing ring atom. For example, in `C1CCCCC1`, the first carbon has a number '1' which connects by a single bond with the last carbon which also has a number '1'. The resulting structure is cyclohexane\n",
    "    - **Branches** - are specified by enclosing them in parentheses, and can be nested or arranged. For Eg. 2-Propanol is represented by CC(O)C.\n",
    "\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "## What is Categorical Data?\n",
    "Categorical data are variables that contain label values rather than numeric values.\n",
    "Some examples include:\n",
    "\n",
    "- A “pet” variable with the values: “dog” and “cat“.\n",
    "- A “color” variable with the values: “red“, “green” and “blue“.\n",
    "- A “place” variable with the values: “first”, “second” and “third“.\n",
    "\n",
    "Talking about in terms of Bioinformatics, if we are using Machine learning Classifier to classify Cancerous and Normal Tissues cells, we can have label values say \"Lung Cancer\", \"Breast Cancer\", \"Liver Cancer\" and \"Healthy Controls\".\n",
    "We first need to One Hot Encode these Categorical label values and then we can apply Binary or Multi-Class Classifier to achieve classification results.\n",
    "\n",
    "\n",
    "> ### What is the Problem with Categorical Data?\n",
    "Machine Learning is, after all, a bunch of mathematical operations translated to a computer via low-level programming languages.Computers are brilliant when dealing with numbers. So, we must somehow convert our input data to numbers. \n",
    "There are many machine learning algorithms which cannot operate on categorical data directly so they must be converted to a numerical form so all our input variables and output variables will be numeric.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/external-content.duckduckgo.com_.jpeg\" alt=\"Drawing\" style=\"max-width: 500px; width:400%;\"/>\n",
    "</div>\n",
    "\n",
    "**Figure 1** displays the Categorical Encoding requires for our computers to understand the input.\n",
    "\n",
    "> ### How to Convert Categorical Data to Numerical Data?\n",
    "There are many ways to convert categorical values into numerical values.Each approach has its own positive and negative impact on the feature set. Hereby, I would be focusing on 2 main methods: `One-Hot-Encoding` and `Label-Encoder`.\n",
    "Both of these encoders are part of SciKit-learn library (one of the most widely used Python library) and are used to convert text or categorical data into numerical data which the model expects and perform better with.\n",
    "\n",
    "---\n",
    "\n",
    "## One Hot Encoding Concept\n",
    "One hot encoding is a vector representation where all the elements of the vector are 0 except one, which has 1 as its value. For example, [0 0 0 1 0 0] is a one-hot vector.\n",
    "Simply, One hot encoding also known as Binary encoding, is a binary representation of categorical variables as binary vectors.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs12859-018-2523-5/MediaObjects/12859_2018_2523_Fig1_HTML.png?as=webp\" style=\"max-width: 500px; width:400%;\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "**Figure 2a** shows the One Hot Encoding of four DNA nucleotides, a filter kernel with one-dimensional CNN and \n",
    "**Figure 2b** shows One Hot Encoding of Toluene and applying one-dimensional CNN to SMILES linear representations of chemical compound Toluene.\n",
    "\n",
    "Lets take a deeper look into the concept with the help of a simple example that will describe the basic concept of One Hot Encoding, why it is useful and how one can approach towards it.\n",
    "\n",
    "> ### Why Use a One Hot Encoding?\n",
    "A one hot encoding allows the representation of categorical data to be more expressive.\n",
    "Its difficult for many machine learning algorithms to work with categorical data directly that's why the label values which are categorical must be converted into numbers first as a preprocessing step. This is required for both input and output variables that are categorical.\n",
    "We could use an integer encoding directly. This may work for problems where there is a natural ordinal relationship between the categories, and in turn the integer values, such as labels for temperature ‘cold’, warm’, and ‘hot’.\n",
    "There may be problems when there is no ordinal relationship and allowing the representation to lean on any such relationship might be damaging to learning to solve the problem. An example might be the labels ‘dog’ and ‘cat\n",
    "\n",
    "\n",
    "> ### Example of One Hot Encoding\n",
    "Lets take a look at a very simple example to understand this concept.\n",
    "Lets assume we have the “color” variable which has three labels, `RED` , `BLUE` and `GREEN`.\n",
    "All these labels must be converted into numeric form in order to work with our Machine Learning algorithm, this can be done by creating three new columns having all the three labels and use “1” value for the color and “0” values for the other colors as shown in Figure 3.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/OneHotEncoding_eg.png\" style=\"max-width: 700px; width:150%;\" />\n",
    "</div>\n",
    "\n",
    "**Figure 3** shows the visual demonstration of One Hot Encoding done on Color Variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> ###  Advantages of Using One Hot Encoding \n",
    "-  If the cardinality (the number of categories) of the categorical features is low (relative to the amount of data) one-hot encoding will work best. We can use it as input into any Machine Learning model.\n",
    "-  We can create binary representation of our label values which can be useful for binary classification.\n",
    "\n",
    "\n",
    "> ###  Disadvantages of Using One Hot Encoding \n",
    "-  Increase in dimensionality, after adding several columns based on categorical variables, the dataset will be having more dimensions than before and in result it can increase the computational cost.\n",
    "- There is a high chances of multicollinearity due to dummy variables which can affect the performance of our Model.\n",
    "-  Increase [Sparsity](https://en.wikipedia.org/wiki/Sparse_matrix) (sparse array is a matrix in which most of the elements are zero, One Hot Encoding can result in increasing the sparsity of our dataset)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Other similar Transformation\n",
    "\n",
    "### Integer Encoding (Label Encoder)\n",
    "\n",
    "This is called a label encoding or an integer encoding and is easily reversible.\n",
    "[Label Encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) is also a popular encoding technique for handling categorical variables. In this technique, each label is assigned a unique integer based on alphabetical ordering, so that machines can work with it properly.\n",
    "Machine learning algorithms can then decide in a better way on how labels must be operated. \n",
    "It is an important preprocessing step for the structured dataset in supervised learning.\n",
    "\n",
    "> ### Example of Label Encoding\n",
    "Lets take a similar example as above, we have a color variable and we can assign “red” as 0, “green” as 1, and “blue” as 2 as shown in Figure 4.\n",
    "\n",
    "\n",
    "![OneHotEncoding Example](images/label_encoding_example.png)\n",
    "\n",
    "**Figure 4** shows the visual demonstration of Label Encoding of Color variable.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Difference between Label and One Hot Encoding\n",
    "\n",
    "There is not much difference between these two encoding techniques, its mainly depends on the type of data and model we are using. For example if we have categorical features which are not ordinal (dog or cat) then we can use One Hot Encoding. Label encoding works best with ordinal data like Good=0, Better=1, Best=2.\n",
    "Also when there are more categorical variables then its good to choose Label Encoding just to avoid high memory consumption and Sparsity.\n",
    "\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "## Further Readings\n",
    "\n",
    "This section lists some resources for further reading\n",
    "\n",
    "- [What is one hot encoding and when is it used in data science?](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)\n",
    "- [Categorical encoding using Label-Encoding and One-Hot-Encoder](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd#:~:text=One%2DHot%20Encoding%20in%20Python&text=OneHotEncoder%20from%20SciKit%20library%20only,apply%20OneHotEncoder%20on%20column%20Bridge_Types_Cat.)\n",
    "- [Research Article: Convolutional neural network based on SMILES representation of compounds for detecting chemical motif](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2523-5)\n",
    "- [How one can use matplotlib.pyplot.imshow() in Python](https://www.geeksforgeeks.org/matplotlib-pyplot-imshow-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages are installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Importing all the necessary libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "print('All packages are installed successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "## Load and draw molecules\n",
    "\n",
    "Using `Pandas` library, we will first load the data from the [GitHub data repository](https://github.com/volkamerlab/CADDSeminar_2020/blob/master/data/CHEMBL25_activities_EGFR.csv) and then we can draw the molecules using `rdkit.draw` function.\n",
    "Finally we can apply different implementations of `One Hot Encoding` into the SMILES structures.\n",
    "\n",
    "Let's load the data and quickly analyze its column values and also to check if there is any missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA/CHEMBL25_activities_EGFR.csv',\n",
    "                 lineterminator='\\n', index_col=0) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command used to remove warnings\n",
    "# pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe :  (3906, 5)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimension of the data\n",
    "print(\"Shape of dataframe : \", df.shape) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing values\n",
    "df.info() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the dataframe\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas tools and Draw method we can visualize our molecules\n",
    "PandasTools.AddMoleculeColumnToFrame(df, smilesCol='canonical_smiles')\n",
    "Draw.MolsToGridImage(list(df.ROMol[0:10]),\n",
    "                     legends=list(df.chembl_id[0:20]), molsPerRow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Renaming column name ROMol to 2D_Figure to get the proper idea of the column\n",
    "df = df.rename(columns={'ROMol': '2D_Figures'})\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "## Apply One Hot encoding using own implementation\n",
    "\n",
    "Now we can define function which will be useful to create One Hot Encoded Matrix of our SMILES strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column for Encoded values of smiles\n",
    "df['Own_OneHotEncoding'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset of all possible Smiles Characters\n",
    "SMILES_CHARS = [' ', '#', '%', '(',\n",
    "                ')', '+', '-', '.', '/', '0', '1', '2', '3',\n",
    "                '4', '5', '6', '7', '8', '9',\n",
    "                '=', '@', 'A', 'B', 'C', 'F', 'H', 'I', 'K', 'L', 'M',\n",
    "                'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Z',\n",
    "                '[', '\\\\', ']', 'a', 'b', 'c', 'e', 'g', 'i',\n",
    "                'l', 'n', 'o', 'p', 'r', 's', 't', 'u']\n",
    "# Convert the dataset into dictionary\n",
    "smi2index = dict((c, i)for i, c in enumerate(SMILES_CHARS))\n",
    "\n",
    "\n",
    "# Function defined to create One Hot Encoded Matrix\n",
    "def smiles_encoder(smiles, length):\n",
    "    \"\"\"Function defined to One Hot Encode SMILES strings\n",
    "       using all possible 56 characters defined\n",
    "    Parameters\n",
    "    ----------\n",
    "          smiles(string): SMILES strings\n",
    "          length(int): length of the SMILE string\n",
    "    Returns\n",
    "    -------\n",
    "          ndarray: return One Hot Encoded matrix\n",
    "    \"\"\"\n",
    "    smilesMatrix = np.zeros((len(SMILES_CHARS), length), dtype=int)\n",
    "    for i, c in enumerate(smiles, 0):\n",
    "        smilesMatrix[smi2index[c], i] = 1\n",
    "    return smilesMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the smiles in the df and\n",
    "# apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    strings = df['canonical_smiles'].iloc[i]\n",
    "    df['Own_OneHotEncoding'].iloc[i] = smiles_encoder(strings, len(strings))\n",
    "end = timer()\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "smiles_encoder_Time = end - start\n",
    "print(str(smiles_encoder_Time) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using Own Implementation (unequal dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Matplotlib` is a plotting library for the Python programming language and its numerical mathematics extension NumPy. `Pyplot` is a state-based interface to a Matplotlib module which provides a MATLAB-like interface.\n",
    "The [imshow()](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.imshow.html) function in pyplot module of matplotlib library is used to display data as an image; i.e. on a 2D space.\n",
    "\n",
    "Now we can visualize our One Hot encoded strings using imshow() function as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First element's One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix1 = df.iloc[0]['Own_OneHotEncoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix1, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Length of Individual string')\n",
    "plt.ylabel('Possible char in SMILES (56)')\n",
    "plt.title('Visualization of One Hot Encoded Matrix')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'type' of matrix array\n",
    "type(First_OneHotEncoded_matrix1) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the First_one_hot_encoded_matrix\n",
    "First_OneHotEncoded_matrix1.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another One Hot Encoded Matrix\n",
    "Next_OneHotEncoded_matrix2 = df.iloc[1]['Own_OneHotEncoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(Next_OneHotEncoded_matrix2, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Length of Individual string')\n",
    "plt.ylabel('Possible char in SMILES (56)')\n",
    "plt.title('Visualization of One Hot Encoded Matrix')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the Second OneHotEncoded_matrix\n",
    "Next_OneHotEncoded_matrix2.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "## Function defined to Preprocess the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we have noticed from above visualizations, that all the SMILES strings have unequal dimension because it calculates the individual string length, but its better to make the dimension equal for all the SMILES strings for better performance of ML models. In order to achieve this first, we searched for the string with Max Length using [len()](https://www.geeksforgeeks.org/python-string-length-len/) method \n",
    "- By implementing the above method, we can get the max length of the SMILES strings and pass that an argument in our function for all the strings.\n",
    "\n",
    "-----\n",
    "\n",
    "- Second, in the above function, we have created a dataset of 56 possible smiles characters, but to optimize our one hot encoding, we  reconsidered using all the 56 characters.\n",
    "- We can assume that all the characters won't be present in our SMILES structures, so we looked for all the unique characters present in the SMILES.\n",
    "\n",
    "------\n",
    "- Third, I would like to point out that many elements in our periodic table has two alphabets in their name for example 'Cl(Chloride)' and thats commonly present in our SMILES structure but if we use the above 'smiles_encoder' function then we will be splitting Cl into two characters 'C' and 'l' and that would lead to discrepancies, so searching this way for each unique characters and encoding them may not be the best possible way.\n",
    "- Hence, we tried searching for all the two alphabetic element in our SMILES by comparing the atoms present in our strings with all the possible elements present in the periodic table and replaced all the two alphabetic elements with one character, for example 'Cl' changed to 'L'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function used to preprocessed the data\n",
    "def PreprocessingData(df):\n",
    "    \"\"\"Function defined which is used to preprocess the SMILES structures.\n",
    "    Parameters\n",
    "    -----------\n",
    "         df: dataframe which requires preprocessing\n",
    "    Returns\n",
    "    --------\n",
    "         df: dataframe with new Processed_canonical_smiles column\n",
    "         unique_char: unique character list\n",
    "         max_len: maximum length of strings of canonical_smiles column\n",
    "    \"\"\"\n",
    "# Calculate max length of the SMILES strings\n",
    "    max_len = df[\"canonical_smiles\"].str.len().max()\n",
    "# Search for unique characters in our SMILES strings\n",
    "    unique_char = set(df.canonical_smiles.apply(list).sum())\n",
    "    upper_chars = ['C', 'O', 'F', 'P', 'N', 'S', 'H', 'B', 'I']\n",
    "    lower_chars = ['l', 'o', 'r', 'n', 'e', 'c', 's']\n",
    "# List of all possible periodic elements\n",
    "    Periodic_Elements = ['Ac',\n",
    "                         'Al', 'Am', 'Sb', 'Ar', 'As', 'At', 'Ba',\n",
    "                         'Bk', 'Be', 'Bi', 'Bh', 'B', 'Br', 'Cd', 'Ca',\n",
    "                         'Cf', 'C', 'Ce', 'Cs', 'Cl', 'Cr', 'Co', 'Cn',\n",
    "                         'Cu', 'Cm', 'Ds', 'Db', 'Dy', 'Es', 'Er', 'Eu',\n",
    "                         'Fm', 'Fl', 'F', 'Fr', 'Gd', 'Ga', 'Ge', 'Au',\n",
    "                         'Hf', 'Hs', 'He', 'Ho', 'H', 'In', 'I', 'Ir',\n",
    "                         'Fe', 'Kr', 'La', 'Lr', 'Pb', 'Li', 'Lv',\n",
    "                         'Lu', 'Mg', 'Mn', 'Mt', 'Md', 'Hg', 'Mo',\n",
    "                         'Mc', 'Nd', 'Ne', 'Np', 'Ni', 'Nh', 'Nb',\n",
    "                         'N', 'No', 'Og', 'Os', 'O', 'Pd', 'P',\n",
    "                         'Pt', 'Pu', 'Po', 'K', 'Pr', 'Pm', 'Pa',\n",
    "                         'Ra', 'Rn', 'Re', 'Rh', 'Rg', 'Rb', 'Ru', 'Rf',\n",
    "                         'Sm', 'Sc', 'Sg', 'Se', 'Si', 'Ag', 'Na',\n",
    "                         'Sr', 'S', 'Ta', 'Tc', 'Te', 'Ts', 'Tb', 'Tl', 'Th',\n",
    "                         'Tm', 'Sn',\n",
    "                         'Ti', 'W', 'U', 'V', 'Xe', 'Yb', 'Y', 'Zn', 'Zr']\n",
    "# 'TwoCharcElements' is a list that contains 2 letter elements\n",
    "# which are valid when compared with all the possible Periodic Elements.\n",
    "    TwoCharcElements = []\n",
    "    for upper in upper_chars:\n",
    "        for lower in lower_chars:\n",
    "            ch = upper + lower\n",
    "            if(ch in Periodic_Elements):\n",
    "                TwoCharcElements.append(ch)\n",
    "# 'TwoCharElementsSmiles' is a set that contains all the possible 2 letter elem\n",
    "# in our SMILES strings, that is *specific* to our dataset.\n",
    "    TwoCharElementsSmiles = set()\n",
    "    for x in TwoCharcElements:\n",
    "        for i in range(0, 3906):\n",
    "            if(df['canonical_smiles'].iloc[i].find(x) != -1):\n",
    "                TwoCharElementsSmiles.add(x)\n",
    "# Create a new column having processed canonical SMILES\n",
    "    df['Processed_canonical_smiles'] = \"\"\n",
    "# Replaced all the two letter elements found (Cl, Br, Cn, Se, @@) with one char\n",
    "    for i in range(0, 3906):\n",
    "        element = df['canonical_smiles'].iloc[i]\n",
    "        element = element.replace(\"Cl\", \"L\")\n",
    "        element = element.replace(\"Br\", \"R\")\n",
    "        element = element.replace(\"Cn\", \"X\")\n",
    "        element = element.replace(\"Se\", \"Z\")\n",
    "        element = element.replace(\"@@\", \"$\")\n",
    "        df['Processed_canonical_smiles'].iloc[i] = element\n",
    "    unique_char = set(df.Processed_canonical_smiles.apply(list).sum())\n",
    "    return unique_char, df, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This function is highly specific to the above dataset used, because we have replaced 2 letter elements that were particularly found in the used dataset. One can add two 2 letter elements present in their SMILES strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply One Hot encoding using Own implementation on Preprocessed Data\n",
    "\n",
    "Now we have used the same function 'smiles_encoder' but on processed canonical strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which has one hot encoded smiles using unique characters\n",
    "df['UniqueChar_OneHotEncoding'] = \"\"\n",
    "# Calling function\n",
    "unique_char, df, max_len = PreprocessingData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_char) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of the unique char datset\n",
    "smi2index = dict((c, i) for i, c in enumerate(unique_char))\n",
    "\n",
    "\n",
    "# Function defined to create One Hot Encoded Matrix\n",
    "def smiles_encoder(smiles, maxlen):\n",
    "    \"\"\"Function defined using all unique characters in our\n",
    "       Processed Canonical Smiles structures created\n",
    "       from preprocessed function.\n",
    "    Parameters\n",
    "    ----------\n",
    "        smiles(string): smile data in string\n",
    "        maxlen(int): max length of the SMILES string\n",
    "    Returns\n",
    "    -------\n",
    "        ndarray: return One Hot Encoded matrix with fixed dimension\n",
    "    \"\"\"\n",
    "    smilesMatrix = np.zeros((len(unique_char), maxlen))\n",
    "    for i, c in enumerate(smiles, 0):\n",
    "        smilesMatrix[smi2index[c], i] = 1\n",
    "    return smilesMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the smiles in the dataframe\n",
    "# and apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    strings = df['Processed_canonical_smiles'].iloc[i]\n",
    "    df['UniqueChar_OneHotEncoding'].iloc[i] = smiles_encoder(strings, max_len)\n",
    "end = timer()\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "smiles_encoder_eqDimen = end - start\n",
    "print(str(smiles_encoder_eqDimen) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using Own Implementation (equal dimension) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix3 = df.iloc[0]['UniqueChar_OneHotEncoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix3, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Length of Unique Characters (37)')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (own)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the First OneHotEncoded_matrix\n",
    "First_OneHotEncoded_matrix3.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another One Hot Encoded Matrix\n",
    "Next_OneHotEncoded_matrix4 = df.iloc[1]['UniqueChar_OneHotEncoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(Next_OneHotEncoded_matrix4, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Length of Unique Characters (37)')\n",
    "plt.title('Visualization of One Hot Encoded Matrix(own)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the Second OneHotEncoded_matrix\n",
    "Next_OneHotEncoded_matrix4.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figures, we can conclude that the dimensions are equal for all the string's One Hot Encoded Matrix using `PreprocessingData` and `smiles_encoder` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "## Apply One Hot encoding using implementation in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we proceed with our second implementation from Scikit-learn. We can use [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) from SciKit library but it only takes numerical categorical values, hence any value of string type should be [label_encoded](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) first before one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the SMILES into characters\n",
    "def split(stringData):\n",
    "    \"\"\"Function used to split the SMILES strings into Characters array\n",
    "    Parameters\n",
    "    ----------\n",
    "         stringData(string): string\n",
    "    Returns\n",
    "    -------\n",
    "         array: return character array\n",
    "    \"\"\"\n",
    "    return [char for char in stringData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scikit-learn implementation of One Hot Encoding\n",
    "def sklearn_OneHotEncode(canonical_char):\n",
    "    \"\"\"Function used to label and One Hot Encode the smiles\n",
    "       using sklearn LabelEncoder and OneHotEncoder implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "          canonical_char(array): Canonical character array\n",
    "    Returns\n",
    "    -------\n",
    "          ndarray: return one hot encoded matrix\n",
    "    \"\"\"\n",
    "    # integer encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(canonical_char)\n",
    "    # One Hot encoding\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Functions above first give integer encoded SMILES of the labels and finally One Hot encode the SMILES structures.\n",
    "\n",
    "\n",
    "By default, the OneHotEncoder class will return a more efficient sparse encoding which can be useful in some applications but in this case, we disabled the sparse return type by setting the `sparse=False` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without padding (Unequal Dimension)\n",
    "\n",
    "We can use above defined sklearn_OneHotEncode function to create OneHotEncoded matrix but this will again create unequal dimensions of the matrix because it will first label encode all the characters present in the SMILES strings (individually) and then One Hot Encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which has OneHotEncoded smiles using sklearn implementation\n",
    "df['sklearn_OneHotEncoded_WP'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the smiles in the dataframe\n",
    "# and apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    canonical_char = split(df['Processed_canonical_smiles'].iloc[i])\n",
    "    sklearnOHC = sklearn_OneHotEncode(canonical_char)\n",
    "    df['sklearn_OneHotEncoded_WP'].iloc[i] = sklearnOHC.transpose()\n",
    "end = timer()\n",
    "df.head(2) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "sklearn_time_withoutPadding = end - start\n",
    "print(str(sklearn_time_withoutPadding) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using Scikit-learn implementation(without Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix5 = df.iloc[0]['sklearn_OneHotEncoded_WP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix5, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Possible char in individual SMILES')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (scikit-learn)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the OneHotEncoded_matrix\n",
    "First_OneHotEncoded_matrix5.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be confirmed from above visualization that the our One Hot Encoded matrix from sklearn implementation do not have equal dimensions because sklearn Onehot_encoder takes individual strings as their input.\n",
    "\n",
    "So we thought of making equal dimension of our One Hot Encoded matrix by adding padding to it. It can be either done after One Hot Encoding is performed on the SMILES strings or before One Hot Encoding is performed, after we label encode our SMILES characters.\n",
    "\n",
    "We will be discussing both the scenarios in next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding after One Hot Encoding is Perfomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which has OneHotEncoded smiles using sklearn implementation\n",
    "df['sklearn_OneHotEncoded_later'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined function to add padding after OneHotEncoding\n",
    "def laterPadding(matrix):\n",
    "    \"\"\"Add horizantle and vertical padding to the given matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "          matrix(ndarray): Character array\n",
    "    Returns\n",
    "    -------\n",
    "          ndarray: return padded matrix\n",
    "  \"\"\"\n",
    "    IndexPadding = np.ndarray(shape=(267-len(matrix),\n",
    "                                     len(matrix[0])))\n",
    "    IndexPadding.fill(0)\n",
    "    ColumnPadding = np.ndarray(shape=(267,\n",
    "                                      37-len(matrix[0])))\n",
    "    ColumnPadding.fill(0)\n",
    "    matrix = np.append(matrix, IndexPadding, axis=0)\n",
    "    matrix = np.append(matrix, ColumnPadding, axis=1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all the smiles in the dataframe\n",
    "# and apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    canonical_char = split(df['Processed_canonical_smiles'].iloc[i])\n",
    "    sklearnOHC = sklearn_OneHotEncode(canonical_char)\n",
    "    sklearnOHCPadding = laterPadding(sklearnOHC)\n",
    "    df['sklearn_OneHotEncoded_later'].iloc[i] = sklearnOHCPadding.transpose()\n",
    "end = timer()\n",
    "df.head(2) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "sklearn_time_Later = end - start\n",
    "print(str(sklearn_time_Later) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using Scikit-learn implementation(padding after one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix6 = df.iloc[0]['sklearn_OneHotEncoded_later']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix6, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Char in individual SMILES')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (scikit-learn)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the OneHotEncoded_matrix\n",
    "First_OneHotEncoded_matrix6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another One Hot Encoded Matrix\n",
    "Two_OneHotEncoded_matrix6 = df.iloc[0]['sklearn_OneHotEncoded_later']\n",
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(Two_OneHotEncoded_matrix6, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Char in individual SMILES')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (scikit-learn)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the OneHotEncoded_matrix\n",
    "Two_OneHotEncoded_matrix6.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can observe that our dimensions are equal for all the SMILES strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding before One Hot Encoding is Perfomed\n",
    "\n",
    "In this case we have added padding just after the label encoding or before the One Hot Encoding is performed on SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which has OneHotEncoded smiles using sklearn implementation\n",
    "df['sklearn_OneHotEncoded_initial'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined function to add padding before OneHotEncoding\n",
    "def initialPadding(canonical_char):\n",
    "    \"\"\"Add Padding to the given list before One Hot Encoding\n",
    "       is performed.\n",
    "    Parameters\n",
    "    ----------\n",
    "          canonical_char(array): Character array\n",
    "    Returns\n",
    "    -------\n",
    "          list: return padded character list\n",
    "    \"\"\"\n",
    "    zeroes = [0] * (267-len(canonical_char))\n",
    "    list1 = canonical_char + zeroes\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the SMILES in the dataframe and\n",
    "# apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    canonical_char = split(df['Processed_canonical_smiles'].iloc[i])\n",
    "    canonical_charPadded = initialPadding(canonical_char)\n",
    "    sklearnOHC = sklearn_OneHotEncode(canonical_charPadded)\n",
    "    ColumnPadding = np.ndarray(shape=(267,\n",
    "                                      37-len(sklearnOHC[0])))\n",
    "    ColumnPadding.fill(0)\n",
    "    sklearnOHC = np.append(sklearnOHC, ColumnPadding, axis=1)\n",
    "    df['sklearn_OneHotEncoded_initial'].iloc[i] = sklearnOHC.transpose()\n",
    "end = timer()\n",
    "df.head(2) # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "sklearn_time_initial = end - start\n",
    "print(str(sklearn_time_initial) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using Scikit-learn implementation(padding before one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix7 = df['sklearn_OneHotEncoded_initial'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix7, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Length of Unique Characters (37)')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (own)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the OneHotEncoded_matrix\n",
    "First_OneHotEncoded_matrix7.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "## Apply One Hot encoding using implementation in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is also a very powerful and highly used library mainly for deep-learning tasks. \n",
    "There may be a case where we already have sequences or strings that is already integer encoded, then in that case we can use function called [to_categorical()](https://keras.io/api/utils/) provide by keras library to one hot encode integer data directly, but it always should be integer which may not have a real ordinal relationship and are really just placeholders for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use keras implementation of One Hot Encoding\n",
    "def keras_OneHotEncode(canonical_char):\n",
    "    \"\"\"\n",
    "    Function to one hot encode the smiles using keras\n",
    "    implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "         canonical_char(array): Canonical character array\n",
    "    Returns\n",
    "    -------\n",
    "         ndarray: return one hot encoded matrix\n",
    "    \"\"\"\n",
    "    # integer encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(canonical_char)\n",
    "    # one hot encode\n",
    "    encoded = to_categorical(integer_encoded)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Padding (unequal dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which has OneHotEncoded smiles using keras implementation\n",
    "df['keras_OneHotEncoded'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for loop to iterate over all the smiles in the\n",
    "# dataframe and apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    canonical_char = split(df['canonical_smiles'].iloc[i])\n",
    "    kerasOHC = keras_OneHotEncode(canonical_char)\n",
    "    df['keras_OneHotEncoded'].iloc[i] = kerasOHC.transpose()\n",
    "end = timer()\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "keras_time = end - start\n",
    "print(str(keras_time) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix8 = df.iloc[0]['keras_OneHotEncoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix8, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Length of String')\n",
    "plt.ylabel('Possible char in individual SMILES')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (keras)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the OneHotEncoded_matrix\n",
    "First_OneHotEncoded_matrix8.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With padding (equal dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which has OneHotEncoded smiles using keras implementation\n",
    "df['keras_OneHotEncoded_padding'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to iterate over all the smiles in the\n",
    "# dataframe and apply the  function\n",
    "start = timer()\n",
    "for i in range(0, 3906):\n",
    "    canonical_char = split(df['canonical_smiles'].iloc[i])\n",
    "    kerasOHC = keras_OneHotEncode(canonical_char)\n",
    "    kerasOHCPadding = laterPadding(kerasOHC)\n",
    "    df['keras_OneHotEncoded_padding'].iloc[i] = kerasOHCPadding.transpose()\n",
    "end = timer()\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time required for execution\n",
    "keras_time_WP = end - start\n",
    "print(str(keras_time_WP) + ' secs') # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization with Matplotlib.imshow() function of One Hot Encoded Matrix using keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First One Hot Encoded Matrix\n",
    "First_OneHotEncoded_matrix9 = df.iloc[0]['keras_OneHotEncoded_padding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of One Hot Encoded array using matplotlib imshow()\n",
    "im = plt.imshow(First_OneHotEncoded_matrix9, cmap='hot', interpolation='None')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.xlabel('Maximum length of String (267)')\n",
    "plt.ylabel('Number of characters in SMILES')\n",
    "plt.title('Visualization of One Hot Encoded Matrix (keras)')\n",
    "# plt.axis('auto')\n",
    "plt.show() # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension\n",
    "First_OneHotEncoded_matrix9.shape # TODO:CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe with all the OHE matrices\n",
    "df.head() # TODO:CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion \n",
    "\n",
    "As we can notice from my above implementations, the execution time varies with different implementations, \n",
    "- **Unequal Dimension** (when no padding was performed)\n",
    "    - Unexpectedly, our own 'smiles_encoder' function worked the best with 0.89 sec execution time followed by 'Keras' implementation with 1.48 sec and One Hot Encoding with 'Scikit-learn' implementation executed with 2.42 secs, the highest.  But since we have different dimensions then it won't be much useful for our Machine Learning Models.\n",
    "- **Equal Dimension** (when padding was performed)\n",
    "    - Surprisingly, even after creating equal dimensions (adding padding), my own functions 'PreprocessingData' along with 'smiles_encoder' again outperformed the other two implementations with execution time of 1.02 secs whereas sklearn required approximately 3.0 secs and keras 1.85 secs. In my opinion, it happened because of additional padding performed on the strings.\n",
    "    \n",
    "\n",
    "I would also like to draw your attention for the time execution difference in Scikit-learn Implementation when Padding performed\n",
    "- **Before One Hot Encoding** : Time required was 3.0 secs approx.\n",
    "- **After One Hot Encoding** : Time required was 2.7 secs approx.\n",
    "\n",
    "One possible reason of this time difference could be, if we perform padding after the label encoding, then we will be having more characters to one hot encode as compared to just add padding after one encoded is accomplished.\n",
    "\n",
    "**Note:** Execution Timings might differ depending upon the enviornment used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were several challenges faced during the task, for instance:\n",
    "- Making equal dimensions.\n",
    "- Finding unique characters, that lead to finding of 2 letter elements.\n",
    "- Specific `Sc` Element because after searching for 2 letter elements, we found this element, but in our SMILES both 'S' and 'c' are present. So if we would have replaced 'Sc' with single letter element then it might have affected our strings. So we assumed that since Sc is a metallic element and its not present oftently present in SMILES, we did not replace this element."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
